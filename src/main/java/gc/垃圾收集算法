### 分代假说
* 弱分代假说(Weak Generational Hypothesis):绝大多数对象都是朝生夕灭的
* 强分代假说(Strong Generational Hypothesis):熬过越多次垃圾收集过程的对象就越难以消
亡。
* 跨代引用假说(Intergenerational Reference Hypothesis):跨代引用相对于同代引用来说仅占极
少数。
- 有了跨代引用假说，也不必浪费空间专门记录
每一个对象是否存在及存在哪些跨代引用,只需在新生代上建立一个全局的数据结构(该结构被称
为“记忆集”,Remembered Set)。这个结构把老年代划分成若干小块,标识出老年代的哪一块内存会
存在跨代引用。此后当发生M inor GC时,只有包含了跨代引用的小块内存里的对象才会被加入到GC
Roots进行扫描。
- 记忆集是一种抽象的概念，最经典的实现是“#_*卡表*_#”(Card Table)
- 卡表最简单的形式可以只是一个字节数组 ,而HotSpot虚拟机确实也是这样做的。以下这行代
码是HotSpot默认的卡表标记逻辑  : _*CARD_TABLE[this address >> 9] =0*_;
字节数组CARD_TABLE的每一个元素都对应着其标识的内存区域中一块特定大小的内存块,这个
内存块被称作“卡页”(Card Page)。一般来说,卡页大小都是以2的N次幂的字节数,通过上面代码可
以看出HotSpot中使用的卡页是2的9次幂,即512字节(地址右移9位,相当于用地址除以512)。那如
果卡表标识内存区域的起始地址是0x0000的话,数组CARD_TABLE的第0、1、2号元素,分别对应了
地址范围为0x0000~0x01FF、0x0200~0x03FF、0x0400~0x05FF的卡页内存块
- 一个卡页的内存中通常包含不止一个对象,只要卡页内有一个(或更多)对象的字段存在着跨代
指针,那就将对应卡表的数组元素的值标识为1,称为这个元素变脏(Dirty),没有则标识为0。在垃
圾收集发生时,只要筛选出卡表中变脏的元素,就能轻易得出哪些卡页内存块中包含跨代指针,把它
们加入GC Roots中一并扫描。

### 写屏障
* 用来解决卡表的维护问题（变脏时间点原则上应该发生在引用类型字段赋值的那一刻）
* 这里提到的“写屏障”,以及后面在低延迟收集器中会提到的“读屏障”与解决并发乱序执行问题中的“内存屏障” 区分开来,避免混淆
* 写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切
面 ,在引用对象赋值时会产生一个环形(Around)通知,供程序执行额外的动作,也就是说赋值的
前后都在写屏障的覆盖范畴内。在赋值前的部分的写屏障叫作写前屏障(Pre-Write Barrier),在赋值
后的则叫作写后屏障(Post-Write Barrier)。HotSpot虚拟机的许多收集器中都有使用到写屏障,但直
至G1收集器出现之前,其他收集器都只用到了写后屏障。
* void oop_field_store(oop* field, oop new_value) {
// 引用字段赋值操作
*field = new_value;
// 写后屏障,在这里完成卡表状态更新
post_write_barrier(field, new_value);
}
* 应用写屏障后,虚拟机就会为所有赋值操作生成相应的指令,一旦收集器在写屏障中增加了更新
卡表操作,无论更新的是不是老年代对新生代对象的引用,每次只要对引用进行更新,就会产生额外
的开销,不过这个开销与M inor GC时扫描整个老年代的代价相比还是低得多的。
* 除了写屏障的开销外,卡表在高并发场景下还面临着“#_*伪共享*_#”(False Sharing)问题(MESI－CPU缓存一致性协议导致)。伪共享是处
理并发底层细节时一种经常需要考虑的问题,现代中央处理器的缓存系统中是以缓存行(Cache Line)
为单位存储的,当多线程修改互相独立的变量时,如果这些变量恰好共享同一个缓存行,就会彼此影
响(写回、无效化或者同步)而导致性能降低,这就是伪共享问题。
假设处理器的缓存行大小为64字节,由于一个卡表元素占1个字节,64个卡表元素将共享同一个缓
存行。这64个卡表元素对应的卡页总的内存为32KB(64×512字节),也就是说如果不同线程更新的对
象正好处于这32KB的内存区域内,就会导致更新卡表时正好写入同一个缓存行而影响性能。为了避免
伪共享问题,一种简单的解决方案是不采用无条件的写屏障,而是先检查卡表标记,只有当该卡表元素未被标记过时才将其标记为变脏,即将卡表更新的逻辑变为以下代码所示:
* if (CARD_TABLE [this address >> 9] != 0)
CARD_TABLE [this address >> 9] = 0;
* 在JDK 7之后,HotSpot虚拟机增加了一个新的参数-XX:+UseCondCardM ark,用来决定是否开启
卡表更新的条件判断。开启会增加一次额外判断的开销,但能够避免伪共享问题,两者各有性能损
耗,是否打开要根据应用实际运行情况来进行测试权衡。

### MESI－CPU缓存一致性协议
* M: 被修改（Modified)
- 该缓存行只被缓存在该CPU的缓存中，并且是被修改过的（dirty),即与主存中的数据不一致，该缓存行中的内存需要在未来的某个时间点（允许其它CPU读取请主存中相应内存之前）写回（write back）主存。当被写回主存之后，该缓存行的状态会变成独享（exclusive)状态。
* E: 独享的（Exclusive)
- 该缓存行只被缓存在该CPU的缓存中，它是未被修改过的（clean)，与主存中数据一致。该状态可以在任何时刻当有其它CPU读取该内存时变成共享状态（shared)。同样地，当CPU修改该缓存行中内容时，该状态可以变成Modified状态。
* S:共享的（Shared)
- 该状态意味着该缓存行可能被多个CPU缓存，并且各个缓存中的数据与主存数据一致（clean)，当有一个CPU修改该缓存行中，其它CPU中该缓存行可以被作废（变成无效状态（Invalid））。
* I: 无效的（Invalid）
- 该缓存是无效的（可能有其它CPU修改了该缓存行）。

### 标记清除算法
* 算法分为“标记”和“清除”两个阶段:首先标记出所有需要回
收的对象,在标记完成后,统一回收掉所有被标记的对象,也可以反过来,标记存活的对象,统一回
收所有未被标记的对象。标记过程就是对象是否属于垃圾的判定过程.
* 缺点：
- 第一个是执行效率不稳定,如果Java堆中包含大量对
象,而且其中大部分是需要被回收的,这时必须进行大量标记和清除的动作,导致标记和清除两个过
程的执行效率都随对象数量增长而降低;
- 第二个是内存空间的碎片化问题,标记、清除之后会产生大
量不连续的内存碎片,空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找
到足够的连续内存而不得不提前触发另一次垃圾收集动作。

### 标记-复制算法
* 将可用内存按容量划分为大小相等的两块,每次只使用其中的一块。当这一块的内存用完了,就将还存活着
的对象复制到另外一块上面,然后再把已使用过的内存空间一次清理掉。如果内存中多数对象都是存
活的,这种算法将会产生大量的内存间复制的开销,但对于多数对象都是可回收的情况,算法需要复
制的就是占少数的存活对象,而且每次都是针对整个半区进行内存回收,分配内存时也就不用考虑有
空间碎片的复杂情况,只要移动堆顶指针,按顺序分配即可
* 缺点：浪费空间
* 在1989年,Andrew Appel针对具备“朝生夕灭”特点的对象(98%的对象熬不过第一轮收集),提出了一种更优化的半区复制分代策
略,现在称为“Appel式回收”。
- HotSpot虚拟机的Serial、ParNew等新生代收集器均采用了这种策略来设
计新生代的内存布局 [1] 。Appel式回收的具体做法是把新生代分为一块较大的Eden空间和两块较小的
Survivor空间,每次分配内存只使用Eden和其中一块Survivor。发生垃圾搜集时,将Eden和Survivor中仍
然存活的对象一次性复制到另外一块Survivor空间上,然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1,也即每次新生代中可用内存空间为整个新
生代容量的90%(Eden的80%加上一个Survivor的10%),只有一个Survivor空间,即10%的新生代是会
被“浪费”的。
- Appel式回收还有一个充当罕见情况的“逃生门”的安
全设计,当Survivor空间不足以容纳一次M inor GC之后存活的对象时,就需要依赖其他内存区域(实
际上大多就是老年代)进行分配担保(Handle Promotion)

### 标记-整理算法
* 移动存活对象,尤其是在老年代这种每次回收都有大量对象存活区域,移动存活对象并更新
所有引用这些对象的地方将会是一种极为负重的操作,而且这种对象移动操作必须全程暂停用户应用
程序才能进行 ,这就更加让使用者不得不小心翼翼地权衡其弊端了,像这样的停顿被最初的虚拟机
设计者形象地描述为“Stop The World”。
* 从垃圾收集的停顿时间来看,不移动对象停顿时间会更短,甚至可以不需要停顿,但是从整
个程序的吞吐量来看,移动对象会更划算。即使不移动对象会使得收集器的效率提升一些,但因内存分配和访问相比垃圾收集频率要
高得多,这部分的耗时增加,总吞吐量仍然是下降的。
* HotSpot虚拟机里面关注吞吐量的Parallel Scavenge收集器是基于标记-整理算法的,而关注延迟的CM S收集器则是基于标记-清除算法的(内存空间的碎片化程度已经
大到影响对象分配时,再采用标记-整理算法收集一次,以获得规整的内存空间)